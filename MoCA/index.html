<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="description"
    content="Compositional 3D asset generation -- generate part-composed objects or instance-composed scenes from a single image." />
  <meta name="keywords" content="3D Part generation, Compositional 3D generation, Diffusion model" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>
    MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation
  </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

  <link rel="stylesheet" href="./static/css/bulma.min.css" />
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="./static/css/index.css" />
  <link rel="icon" href="./static/images/hunyuan-logo.png" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three/examples/js/loaders/GLTFLoader.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three/examples/js/controls/OrbitControls.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@8/swiper-bundle.min.css" />
  <script src="https://cdn.jsdelivr.net/npm/swiper@8/swiper-bundle.min.js"></script>

  <!--  Scene Viewer -->
  <link rel="stylesheet" href="modules/SceneViewer/scene-viewer.css" />

  <!-- Video Viewer -->
  <link rel="stylesheet" href="modules/VideoViewer/video-viewer.css" />
</head>

<body>
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center">
        <a class="navbar-item" href="https://lizhiqi49.github.io/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

      </div>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <b>MoCA</b>: <u>M</u>ixture-<u>o</u>f-<u>C</u>omponents <u>A</u>ttention for Scalable Compositional 3D Generation
            </h1>
            <div class="is-size-5 publication-authors">
              <a href="https://lizhiqi49.github.io/" target="_blank">Zhiqi Li</a><sup>1,2</sup>,
              <a href="https://github.com/haoduoylg5474" target="_blank">Wenhuan Li</a><sup>3</sup>,
              <a href="https://tengfei-wang.github.io/" target="_blank">Tengfei Wang</a><sup>3,†</sup>,
              <a href="https://zhenwwang.github.io/" target="_blank">Zhenwei Wang</a><sup>3</sup>,
              Junta Wu<sup>3</sup>,
              <a href="https://www.whyy.site/" target="_blank">Haoyuan Wang</a><sup>3</sup>,<br />
              <a href="https://yhyang-myron.github.io/" target="_blank">Yunhan Yang</a><sup>3</sup>,
              <a href="https://huanngzh.github.io/" target="_blank">Zehuan Huang</a><sup>3</sup>,
              <a href="https://yang-l1.github.io/" target="_blank">Yang Li</a><sup>3</sup>,
              Chunchao Guo<sup>3,†</sup>,
              <a href="https://ethliup.github.io/" target="_blank">Peidong Liu</a><sup>2</sup>
            </div>

            <div class="is-size-5 publication-authors">
              <sup>1</sup>Zhejiang University &nbsp;&nbsp; <sup>2</sup>Westlake University &nbsp;&nbsp; <sup>3</sup>Tencent Hunyuan
              <br />
              <sup>†</sup>Corresponding Authors 
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/xxxx.xxxxx" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/lizhiqi49/MoCA" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Model Link. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/tencent/Hunyuan3D-Part" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-database"></i>
                    </span>
                    <span>Model</span>
                  </a>
                </span> -->
                <!-- Demo Link. -->
                <!-- <span class="link-block">
                  <a href="https://huggingface.co/spaces/tencent/Hunyuan3D-Part"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-smile"></i>
                    </span>
                    <span>Demo</span>
                  </a>
                </span> -->
              </div>
            </div>

            <div class="is-size-5 publication-authors">
              <hr style="
                    width: 100%;
                    height: 0.7px;
                    background-color: rgba(0, 0, 0, 0.665);
                    margin-top: 1em;
                  " />
              Generate complex compositional 3D assets from a single image.
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <br />
          <img src="./assets/images/teaser_v2.jpg" class="" alt="" />
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Compositionality is critical for 3D object and scene generation, but existing part-aware 3D generation methods suffer from poor scalability due to quadratic global attention costs when increasing the number of components. In this work, we present <b>MoCA</b>, a compositional 3D generative model with two key designs: (1) <b>importance-based component routing</b> that selects top-k relevant components for sparse global attention, and (2) <b>unimportant components compression</b> that preserve contextual priors of unselected components while reducing computational complexity of global attention. With these designs, MoCA enables efficient, fine-grained compositional 3D asset creation with scalable number of components. Extensive experiments show MoCA outperforms baselines on both compositional object and scene generation tasks. 
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <!-- Scripts Start -->
  <script type="module">
    import { ViewerModule } from "./modules/SceneViewer/scene-viewer.js";

    const viewer = new ViewerModule(
      ".scene-viewer",
      [
        "001",
        "002",
        "003",
        "004",
        "005",
        "006",
        "007",
        "008",
        "009",
        "010",
        "011",
        "012",
        "013",
        "014",
        "015",
      ],
      "assets/models",
      "assets/images"
    );
    viewer.init();
  </script>
  <!-- Scripts End -->

  <section class="section" style="padding-top: 0">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <div class="has-text-centered">
            <h2 class="title is-3">Interactive Results</h2>
          </div>
          <div class="scene-viewer">
            <!-- Scene Viewer -->
            <div id="loading-overlay">
              <div class="loading-spinner"></div>
            </div>
            <div id="viewer-container"></div>
            <div id="button-block" style="text-align: center; margin: 10px auto;"></div>
            <div class="swiper">
              <div class="swiper-button-prev"></div>
              <div class="swiper-button-next"></div>
              <div class="swiper-wrapper" id="image-slider"></div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="has-text-centered">
        <h2 class="title is-3">Method Overview</h2>
      </div>
      <br />
      <div class="columns is-centered">
        <div class="column is-full-width">
          <br />
          <img src="./assets/images/pipeline.jpg" class="" alt="" />
          <b>Overview of MoCA.</b> Our DiT model starts with packing each component's latents using several learnable queries through a cross-attention layer. Random ID embeddings are applied to distinguish different components. Then, each component's full latents and compressed version are fed into our DiT model, which is comprised with interleaved local attention blocks and our proposed Mixture-of-Components Attention blocks.  Finally, the clean latents of all components are separately decoded to the global space by a frozen shape decoder to form the final 3D asset.
        </div>
      </div>
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <img src="./assets/images/global_attn.jpg" style="width: 60%;" alt="" />
        <div class="has-text-justified">
        <b>Illustration of Mixture-of-Components Attention.</b> The calculation stream for component $\mathbf{c}_i$ is highlighted. This procedure is permutation-invariant across all components.
        </div>
      </div>
    </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <div class="has-text-centered">
            <h2 class="title is-3">Instance-Composed Scene Generation</h2>
          </div>
          <br />
          <div class="has-text-justified">
            TBD...
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="section">
    <div class="container is-max-desktop">
      <div class="has-text-centered">
        <h2 class="title is-3">Geometry Super-resolution</h2>
      </div>
      <br />
      <div class="columns is-centered">
        <div class="column is-full-width">
          <br />
          <img src="./assets/images/geo_super.png" class="" alt="" />
          By representing a part with the same number of tokens as the overall object, we can achieve geometry
          super-resolution.
        </div>
      </div>
    </div>
  </section> -->

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="has-text-centered">
        <h2 class="title">BibTeX</h2>
      </div>
      <div class="columns is-centered has-text-centered" style="padding-bottom: 1.5rem">
        <div class="column is-four-fifths">
          <div class="content has-text-justified">
            <pre><code>@article{li2025moca,
    title={MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation},
    author={Li, Zhiqi and Li, Wenhuan and Wang, Tengfei and Wang, Zhenwei and Wu, Junta and Wang, Haoyuan and Yang, Yunhan and Huang, Zehuan and Li, Yang and Liu, Peidong and others},
    journal={arXiv preprint arXiv:xxxx.xxxxx},
    year={2025}
}</code></pre>
          </div>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p style="text-align: center">
              This project page is adapted from 
              <a href="https://github.com/yanxinhao/yanxinhao.github.io/tree/master/Projects/X-Part"
                target="_blank">X-Part-Page</a>. The
              website template is borrowed from
              <a href="https://nerfies.github.io/" target="_blank">Nerfies</a> and
              <a href="https://vast-ai-research.github.io/HoloPart/" target="_blank">Holopart-Page</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>

</html>
